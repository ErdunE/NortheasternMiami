{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeacd43d-c675-4077-8a3d-402a12210f51",
   "metadata": {},
   "source": [
    "# CS5100 - Assignment 6\n",
    "**Student:** Erdun E  \n",
    "**Assignment:** 06  \n",
    "**Course:** CS5100 Foundations of Artificial Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c10af96-908b-4048-b0db-a023473dd93b",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3b0489-7067-4dfd-bdb6-0745e9b32387",
   "metadata": {},
   "source": [
    "### a. Active and passive sensing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9242a787-acdc-41f9-a751-c8cccf7e5b26",
   "metadata": {},
   "source": [
    "- Active Sensing Definition\n",
    "    - Active sensing sends energy (like light or sound) into the environment and measures how it reflects back. This allows the system to control sensing conditions.\n",
    "- Example\n",
    "    - LiDAR emits laser pulses to map its surroundings.\n",
    "- Passive Sensing Definition\n",
    "    - Passive sensing collects energy already present in the environment, without sending out signals. It is less intrusive and more energy-efficient.\n",
    "- Example\n",
    "    - A camera records sunlight reflected from objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97948610-1944-4311-b18e-1b9f7db68385",
   "metadata": {},
   "source": [
    "### b. Image feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faaf6de-e23a-496f-ad86-86691a68e8c0",
   "metadata": {},
   "source": [
    "- Definition\n",
    "    - An image feature is a distinctive pattern or property in an image that helps describe its content. Features are used to detect, match, or recognize objects.\n",
    "- Example\n",
    "    - Edges and corners are common features for object detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6ae1b8-5bfa-49ff-bba4-5074bc97ed3e",
   "metadata": {},
   "source": [
    "### c. Object model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3196d7eb-06bb-46f3-83ff-92502eaa8afe",
   "metadata": {},
   "source": [
    "- Definition\n",
    "    - An object model is a simplified representation of a real-world object used in computer vision to detect or track it. It can describe the shape, appearance, or structure of the object.\n",
    "- Example\n",
    "    -  A 3D model of a car used for autonomous driving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06975cae-f632-4fb0-b53a-e417ad23fbb6",
   "metadata": {},
   "source": [
    "### d. Rendering model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20514928-facc-4e64-b0e2-077a4fc6f3a3",
   "metadata": {},
   "source": [
    "- Definition\n",
    "    - A rendering model defines how light, materials, and surfaces interact to produce a 2D image from a 3D scene. It simulates effects like shading, lighting, and texture.\n",
    "- Example\n",
    "    - The Phong model is often used to create smooth lighting on 3D objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86527b37-3839-4fb8-9472-cc00c8612067",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f8c38-8860-4941-9115-69e27ae83346",
   "metadata": {},
   "source": [
    "### Comparison Point 1 Architecture Design Principles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38403dc-e6f0-4f3b-a21d-afe6523b3aac",
   "metadata": {},
   "source": [
    "- CNN: Builds hierarchical local features using convolutional filters and pooling layers (Dosovitskiy et al., 2020).\n",
    "- ViT: Divides images into patches and applies self-attention to model global relationships (Dosovitskiy et al., 2020).\n",
    "- MLP-Mixer: Uses fully connected layers for mixing spatial and channel information without convolutions or attention (Tolstikhin et al., 2021)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fddd8f-923b-417f-bc9c-e3389df8c5d2",
   "metadata": {},
   "source": [
    "### Comparison Point 2 Computational Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1897510e-4791-41ef-9e66-1a9bfe584aeb",
   "metadata": {},
   "source": [
    "- CNN: Computationally efficient and well-optimized for small images and edge devices. Its local operations reduce the overall complexity (Applied Sciences, 2023).\n",
    "- ViT: Has higher computational cost due to self-attention across all patches, especially for high-resolution images (Dosovitskiy et al., 2020).\n",
    "- MLP-Mixer: Training is about 3× faster than ViT and achieves excellent throughput performance, though dense layers can scale poorly on very large inputs (Tolstikhin et al., 2021)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926e2a8b-b3fa-40dd-bc71-d969d485700e",
   "metadata": {},
   "source": [
    "### Comparison Point 3 Data Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa273fd-3d21-4649-8341-87ae10382c0d",
   "metadata": {},
   "source": [
    "- CNN: Performs well even with small datasets due to strong inductive bias and local feature extraction (Applied Sciences, 2023).\n",
    "- ViT: Requires large-scale datasets for pre-training to achieve good performance since it lacks built-in locality priors (Dosovitskiy et al., 2020).\n",
    "- MLP-Mixer: Needs as much data as ViT for small datasets but scales very well with extremely large datasets (Tolstikhin et al., 2021)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7373132-2fa8-44e6-be33-1b4c5faca605",
   "metadata": {},
   "source": [
    "### Comparison Point 4 Adversarial Robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a5a8e-7ddd-4529-b1a5-79230496fb65",
   "metadata": {},
   "source": [
    "- CNN: Well-studied for adversarial robustness, but still vulnerable to carefully crafted perturbations (Benz et al., 2021).\n",
    "- ViT: Shows higher robustness to adversarial attacks compared to CNN due to its global attention mechanism (Benz et al., 2021).\n",
    "- MLP-Mixer: Demonstrates better robustness than CNN in standard attacks but shows extreme vulnerability to universal adversarial perturbations (Benz et al., 2021)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3e7dd7-cf11-4115-b74b-cae18bcbbf9c",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5c869c-5d5c-41f5-81f5-d1c6837f0a27",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This section implements a simple vehicle detection system using OpenCV’s Deep Neural Network (DNN) module with a pre-trained YOLO model. The system processes a video, detects vehicles in each frame, and highlights them with bounding boxes in real time.  \n",
    "\n",
    "Vehicle detection is widely used in traffic monitoring, parking assistance, and surveillance systems. In this implementation, we use YOLO (You Only Look Once), a state-of-the-art object detection algorithm known for its balance between speed and accuracy.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353c448c-8dec-4a2b-90c2-3c8bc47eeca8",
   "metadata": {},
   "source": [
    "### Video Source\n",
    "\n",
    "The video used in this project is `cars.mp4`, an official sample video included with the OpenCV library. It is provided for educational purposes and demonstrates a road scene with vehicles moving in traffic.  \n",
    "\n",
    "This video was selected because it is lightweight, easy to process, and avoids potential copyright issues, making it ideal for academic use.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a85c56-2e9b-4534-931b-523d85556f85",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91c752ba-937a-4029-ae69-ae7028cc9c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolov4.weights already exists. Skipping download.\n",
      "yolov4.cfg already exists. Skipping download.\n",
      "coco.names already exists. Skipping download.\n",
      "\n",
      "Libraries imported successfully!\n",
      "OpenCV version: 4.12.0\n",
      "Configuration loaded:\n",
      "- Confidence threshold: 0.5\n",
      "- NMS threshold: 0.4\n",
      "- Input size: 416x416\n",
      "\n",
      "Attempting to load YOLO model...\n",
      "YOLO model loaded successfully!\n",
      "Classes loaded: 80 classes\n",
      "Output layers: ['yolo_139', 'yolo_150', 'yolo_161']\n",
      "\n",
      "detect_vehicles() function defined successfully!\n",
      "Function can detect vehicles in: car, motorcycle, bus, truck classes\n",
      "Detection threshold: 0.5\n",
      "NMS threshold: 0.4\n",
      "\n",
      "process_video() function defined successfully!\n",
      "Function features:\n",
      "- Real-time video processing\n",
      "- Frame-by-frame vehicle detection\n",
      "- Detection count overlay\n",
      "- User controls: 'q' to quit, 'space' to pause\n",
      "\n",
      "==================================================\n",
      "VEHICLE DETECTION SYSTEM READY!\n",
      "==================================================\n",
      "To run the system, execute: main()\n",
      "Make sure you have a video file named 'cars.mp4' in the current directory\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "YOLO Model Files Required (NOT included in submission due to file size):\n",
    "1. yolov4.weights (250MB) - Download from: https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\n",
    "2. yolov4.cfg - Download from: https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4.cfg  \n",
    "3. coco.names - Download from: https://raw.githubusercontent.com/AlexeyAB/darknet/master/data/coco.names\n",
    "\n",
    "Instructions:\n",
    "- Download these files and place them in the same directory as this notebook\n",
    "- Run the cells to test the vehicle detection system\n",
    "\"\"\"\n",
    "\n",
    "# Import required libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Configuration parameters\n",
    "CONFIDENCE_THRESHOLD = 0.5  # Minimum confidence for detection\n",
    "NMS_THRESHOLD = 0.4         # Non-maximum suppression threshold\n",
    "INPUT_WIDTH = 416           # YOLO input width\n",
    "INPUT_HEIGHT = 416          # YOLO input height\n",
    "\n",
    "# YOLO model file paths (these files need to be downloaded)\n",
    "WEIGHTS_PATH = \"yolov4.weights\"     # Pre-trained weights\n",
    "CONFIG_PATH = \"yolov4.cfg\"          # Network configuration\n",
    "CLASSES_PATH = \"coco.names\"         # Class names file\n",
    "\n",
    "# Vehicle class IDs from COCO dataset\n",
    "VEHICLE_CLASSES = [2, 3, 5, 7]  # car, motorcycle, bus, truck\n",
    "\n",
    "# Function to download file if missing\n",
    "def download_file(url, filename):\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"{filename} not found. Downloading from {url} ...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, filename)\n",
    "            print(f\"{filename} downloaded successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {filename}. Please download it manually from: {url}\\nError: {e}\")\n",
    "    else:\n",
    "        print(f\"{filename} already exists. Skipping download.\")\n",
    "\n",
    "# Attempt to download YOLO files if missing\n",
    "download_file(\"https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\", WEIGHTS_PATH)\n",
    "download_file(\"https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4.cfg\", CONFIG_PATH)\n",
    "download_file(\"https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\", CLASSES_PATH)\n",
    "\n",
    "print(\"\\nLibraries imported successfully!\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"- Confidence threshold: {CONFIDENCE_THRESHOLD}\")\n",
    "print(f\"- NMS threshold: {NMS_THRESHOLD}\")\n",
    "print(f\"- Input size: {INPUT_WIDTH}x{INPUT_HEIGHT}\")\n",
    "\n",
    "# Function to load YOLO model\n",
    "def load_yolo_model(weights_path, config_path, classes_path):\n",
    "    \"\"\"\n",
    "    Load YOLO model for vehicle detection\n",
    "    \n",
    "    Args:\n",
    "        weights_path: Path to YOLO weights file\n",
    "        config_path: Path to YOLO config file  \n",
    "        classes_path: Path to class names file\n",
    "    \n",
    "    Returns:\n",
    "        net: OpenCV DNN network\n",
    "        classes: List of class names\n",
    "        output_layers: Output layer names\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if model files exist\n",
    "    if not os.path.exists(weights_path):\n",
    "        print(f\"Warning: {weights_path} not found!\")\n",
    "        print(\"Please download YOLOv4 weights from: https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\")\n",
    "        return None, None, None\n",
    "    \n",
    "    if not os.path.exists(config_path):\n",
    "        print(f\"Warning: {config_path} not found!\")\n",
    "        print(\"Please download YOLOv4 config from: https://github.com/AlexeyAB/darknet/blob/master/cfg/yolov4.cfg\")\n",
    "        return None, None, None\n",
    "        \n",
    "    if not os.path.exists(classes_path):\n",
    "        print(f\"Warning: {classes_path} not found!\")\n",
    "        print(\"Please download COCO names from: https://github.com/AlexeyAB/darknet/blob/master/data/coco.names\")\n",
    "        return None, None, None\n",
    "    \n",
    "    try:\n",
    "        # Load YOLO network\n",
    "        net = cv2.dnn.readNet(weights_path, config_path)\n",
    "        \n",
    "        # Load class names\n",
    "        with open(classes_path, \"r\") as f:\n",
    "            classes = [line.strip() for line in f.readlines()]\n",
    "        \n",
    "        # Get output layer names\n",
    "        layer_names = net.getLayerNames()\n",
    "        output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "        \n",
    "        print(\"YOLO model loaded successfully!\")\n",
    "        print(f\"Classes loaded: {len(classes)} classes\")\n",
    "        print(f\"Output layers: {output_layers}\")\n",
    "        \n",
    "        return net, classes, output_layers\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading YOLO model: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Test loading the model\n",
    "print(\"\\nAttempting to load YOLO model...\")\n",
    "net, classes, output_layers = load_yolo_model(WEIGHTS_PATH, CONFIG_PATH, CLASSES_PATH)\n",
    "\n",
    "# Vehicle detection function\n",
    "def detect_vehicles(frame, net, output_layers, classes):\n",
    "    \"\"\"\n",
    "    Detect vehicles in a single frame\n",
    "    \n",
    "    Args:\n",
    "        frame: Input video frame (numpy array)\n",
    "        net: YOLO network object\n",
    "        output_layers: YOLO output layer names\n",
    "        classes: List of class names\n",
    "    \n",
    "    Returns:\n",
    "        frame: Frame with detection boxes drawn\n",
    "        detections: List of detection results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Return original frame if model not loaded\n",
    "    if net is None:\n",
    "        return frame, []\n",
    "    \n",
    "    # Get frame dimensions\n",
    "    height, width, channels = frame.shape\n",
    "    \n",
    "    # Prepare input blob for YOLO\n",
    "    # Scale pixel values to 0-1, resize to 416x416, swap R and B channels\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.00392, (INPUT_WIDTH, INPUT_HEIGHT), (0, 0, 0), True, crop=False)\n",
    "    \n",
    "    # Set input to the network\n",
    "    net.setInput(blob)\n",
    "    \n",
    "    # Run forward pass through the network\n",
    "    outputs = net.forward(output_layers)\n",
    "    \n",
    "    # Initialize lists to store detection results\n",
    "    boxes = []          # Bounding box coordinates\n",
    "    confidences = []    # Confidence scores\n",
    "    class_ids = []      # Class IDs\n",
    "    \n",
    "    # Process each output layer\n",
    "    for output in outputs:\n",
    "        # Process each detection in the output\n",
    "        for detection in output:\n",
    "            # Extract class scores (first 5 elements are box coordinates and objectness)\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            \n",
    "            # Filter detections: must be a vehicle class with sufficient confidence\n",
    "            if confidence > CONFIDENCE_THRESHOLD and class_id in VEHICLE_CLASSES:\n",
    "                # YOLO returns center coordinates and dimensions, convert to corner coordinates\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                \n",
    "                # Calculate top-left corner coordinates\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                \n",
    "                # Store detection results\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "    \n",
    "    # Apply Non-Maximum Suppression to remove overlapping boxes\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, CONFIDENCE_THRESHOLD, NMS_THRESHOLD)\n",
    "    \n",
    "    # Prepare for drawing bounding boxes\n",
    "    detections = []\n",
    "    colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0)]  # Green, Red, Blue, Yellow\n",
    "    \n",
    "    # Draw bounding boxes for final detections\n",
    "    if len(indexes) > 0:\n",
    "        for i in indexes.flatten():\n",
    "            x, y, w, h = boxes[i]\n",
    "            confidence = confidences[i]\n",
    "            class_id = class_ids[i]\n",
    "            \n",
    "            # Get class name and color\n",
    "            label = f\"{classes[class_id]}: {confidence:.2f}\" if classes else f\"Vehicle: {confidence:.2f}\"\n",
    "            color = colors[class_id % len(colors)]\n",
    "            \n",
    "            # Draw bounding box\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            \n",
    "            # Draw label background\n",
    "            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]\n",
    "            cv2.rectangle(frame, (x, y - label_size[1] - 10), (x + label_size[0], y), color, -1)\n",
    "            \n",
    "            # Draw label text\n",
    "            cv2.putText(frame, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            \n",
    "            # Store detection information\n",
    "            detections.append({\n",
    "                'class': classes[class_id] if classes else 'vehicle',\n",
    "                'confidence': confidence,\n",
    "                'box': [x, y, w, h],\n",
    "                'class_id': class_id\n",
    "            })\n",
    "    \n",
    "    return frame, detections\n",
    "\n",
    "print(\"\\ndetect_vehicles() function defined successfully!\")\n",
    "print(\"Function can detect vehicles in: car, motorcycle, bus, truck classes\")\n",
    "print(\"Detection threshold:\", CONFIDENCE_THRESHOLD)\n",
    "print(\"NMS threshold:\", NMS_THRESHOLD)\n",
    "\n",
    "# Video processing function\n",
    "def process_video(video_path, net, output_layers, classes):\n",
    "    \"\"\"\n",
    "    Process video file and detect vehicles in each frame\n",
    "\n",
    "    Args:\n",
    "        video_path: Path to input video file\n",
    "        net: YOLO network object\n",
    "        output_layers: YOLO output layer names\n",
    "        classes: List of class names\n",
    "    \"\"\"\n",
    "\n",
    "    # Open video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Check if video opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}\")\n",
    "        print(\"Please check if the file exists and is a valid video format\")\n",
    "        return\n",
    "\n",
    "    # Get video properties\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    print(f\"\\nVideo Properties:\")\n",
    "    print(f\"- File: {video_path}\")\n",
    "    print(f\"- Resolution: {width}x{height}\")\n",
    "    print(f\"- FPS: {fps}\")\n",
    "    print(f\"- Total frames: {total_frames}\")\n",
    "    print(f\"- Duration: {total_frames/fps:.2f} seconds\")\n",
    "    print(\"\\nProcessing video... Press 'q' to quit\")\n",
    "\n",
    "    frame_count = 0\n",
    "    total_detections = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"End of video reached\")\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # Detect vehicles\n",
    "        processed_frame, detections = detect_vehicles(frame, net, output_layers, classes)\n",
    "        total_detections += len(detections)\n",
    "\n",
    "        # Overlay frame info\n",
    "        info_text = f\"Frame: {frame_count}/{total_frames} | Vehicles: {len(detections)} | Total: {total_detections}\"\n",
    "        cv2.putText(processed_frame, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Vehicle Detection System', processed_frame)\n",
    "\n",
    "        # Print detections for first few frames\n",
    "        if frame_count <= 5 or len(detections) > 0:\n",
    "            print(f\"Frame {frame_count}: {len(detections)} vehicles detected\")\n",
    "            for i, detection in enumerate(detections):\n",
    "                print(f\"  Vehicle {i+1}: {detection['class']} (confidence: {detection['confidence']:.2f})\")\n",
    "\n",
    "        # Check for key press\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            print(\"User pressed 'q' - stopping video processing\")\n",
    "            break\n",
    "        elif key == ord(' '):  # Pause/resume\n",
    "            print(\"Video paused - press any key to continue\")\n",
    "            cv2.waitKey(0)\n",
    "\n",
    "    # Release and clean up\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)  # Make sure all windows are closed\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\nProcessing Summary:\")\n",
    "    print(f\"- Frames processed: {frame_count}/{total_frames}\")\n",
    "    print(f\"- Total vehicle detections: {total_detections}\")\n",
    "    print(f\"- Average detections per frame: {total_detections/frame_count:.2f}\")\n",
    "    print(\"Processing completed!\")\n",
    "\n",
    "print(\"\\nprocess_video() function defined successfully!\")\n",
    "print(\"Function features:\")\n",
    "print(\"- Real-time video processing\")\n",
    "print(\"- Frame-by-frame vehicle detection\")\n",
    "print(\"- Detection count overlay\")\n",
    "print(\"- User controls: 'q' to quit, 'space' to pause\")\n",
    "\n",
    "def download_sample_video():\n",
    "    \"\"\"Download a sample video for testing vehicle detection\"\"\"\n",
    "    \n",
    "    # Try multiple sample video sources\n",
    "    video_sources = [\n",
    "        {\n",
    "            \"url\": \"https://github.com/opencv/opencv/raw/master/samples/data/vtest.avi\",\n",
    "            \"filename\": \"vtest.avi\",\n",
    "            \"description\": \"OpenCV sample traffic video\"\n",
    "        },\n",
    "        {\n",
    "            \"url\": \"https://sample-videos.com/zip/10/mp4/SampleVideo_1280x720_1mb.mp4\",\n",
    "            \"filename\": \"sample_traffic.mp4\", \n",
    "            \"description\": \"Sample traffic video\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for source in video_sources:\n",
    "        if not os.path.exists(source[\"filename\"]):\n",
    "            try:\n",
    "                print(f\"Downloading {source['description']}...\")\n",
    "                print(f\"URL: {source['url']}\")\n",
    "                urllib.request.urlretrieve(source[\"url\"], source[\"filename\"])\n",
    "                print(f\"Downloaded '{source['filename']}' successfully!\")\n",
    "                return source[\"filename\"]  # Return the downloaded filename\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to download {source['filename']}: {str(e)}\")\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"'{source['filename']}' already exists\")\n",
    "            return source[\"filename\"]\n",
    "    \n",
    "    print(\"Could not download any sample video\")\n",
    "    return None\n",
    "    \n",
    "# Main execution function\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the vehicle detection system\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"🚗 VEHICLE DETECTION SYSTEM 🚗\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load YOLO model\n",
    "    print(\"Loading YOLO model...\")\n",
    "    net, classes, output_layers = load_yolo_model(WEIGHTS_PATH, CONFIG_PATH, CLASSES_PATH)\n",
    "    \n",
    "    if net is None:\n",
    "        print(\"Cannot run system without YOLO model\")\n",
    "        return\n",
    "    \n",
    "    # Define video file path\n",
    "    video_file = \"cars.mp4\"  # OpenCV sample video\n",
    "    \n",
    "    # Check if video file exists\n",
    "    if not os.path.exists(video_file):\n",
    "        print(f\"Video file '{video_file}' not found\")\n",
    "        print(\"Attempting to download sample video...\")\n",
    "        \n",
    "        downloaded_video = download_sample_video()\n",
    "        if downloaded_video:\n",
    "            video_file = downloaded_video\n",
    "            print(f\"Will use downloaded video: {video_file}\")\n",
    "        else:\n",
    "            # List available video files in current directory\n",
    "            video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.flv']\n",
    "            available_videos = [f for f in os.listdir('.') if any(f.lower().endswith(ext) for ext in video_extensions)]\n",
    "            \n",
    "            if available_videos:\n",
    "                print(f\"Available video files found:\")\n",
    "                for video in available_videos:\n",
    "                    print(f\"  - {video}\")\n",
    "                video_file = available_videos[0]\n",
    "                print(f\"Using: {video_file}\")\n",
    "            else:\n",
    "                print(\"No video available for testing\")\n",
    "                return\n",
    "    \n",
    "    print(f\"Video file found: {video_file}\")\n",
    "    print(\"\\nControls:\")\n",
    "    print(\"  - Press 'q' to quit\")\n",
    "    print(\"  - Press 'space' to pause/resume\")\n",
    "    print(\"\\nStarting vehicle detection...\")\n",
    "    \n",
    "    # Process the video\n",
    "    process_video(video_file, net, output_layers, classes)\n",
    "    \n",
    "    print(\"\\nVehicle detection completed!\")\n",
    "\n",
    "# Test function to run the system\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"VEHICLE DETECTION SYSTEM READY!\")\n",
    "print(\"=\"*50)\n",
    "print(\"To run the system, execute: main()\")\n",
    "print(\"Make sure you have a video file named 'cars.mp4' in the current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76f6742a-45f1-4282-a18a-218cdf7daaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🚗 VEHICLE DETECTION SYSTEM 🚗\n",
      "============================================================\n",
      "Loading YOLO model...\n",
      "YOLO model loaded successfully!\n",
      "Classes loaded: 80 classes\n",
      "Output layers: ['yolo_139', 'yolo_150', 'yolo_161']\n",
      "Video file 'cars.mp4' not found\n",
      "Attempting to download sample video...\n",
      "'vtest.avi' already exists\n",
      "Will use downloaded video: vtest.avi\n",
      "Video file found: vtest.avi\n",
      "\n",
      "Controls:\n",
      "  - Press 'q' to quit\n",
      "  - Press 'space' to pause/resume\n",
      "\n",
      "Starting vehicle detection...\n",
      "\n",
      "Video Properties:\n",
      "- File: vtest.avi\n",
      "- Resolution: 768x576\n",
      "- FPS: 10\n",
      "- Total frames: 795\n",
      "- Duration: 79.50 seconds\n",
      "\n",
      "Processing video... Press 'q' to quit\n",
      "Frame 1: 2 vehicles detected\n",
      "  Vehicle 1: car (confidence: 0.94)\n",
      "  Vehicle 2: truck (confidence: 0.90)\n",
      "Frame 2: 2 vehicles detected\n",
      "  Vehicle 1: car (confidence: 0.94)\n",
      "  Vehicle 2: truck (confidence: 0.93)\n",
      "Frame 3: 2 vehicles detected\n",
      "  Vehicle 1: car (confidence: 0.94)\n",
      "  Vehicle 2: truck (confidence: 0.94)\n",
      "Frame 4: 2 vehicles detected\n",
      "  Vehicle 1: car (confidence: 0.94)\n",
      "  Vehicle 2: truck (confidence: 0.93)\n",
      "Frame 5: 2 vehicles detected\n",
      "  Vehicle 1: car (confidence: 0.94)\n",
      "  Vehicle 2: truck (confidence: 0.92)\n",
      "Frame 6: 2 vehicles detected\n",
      "  Vehicle 1: car (confidence: 0.93)\n",
      "  Vehicle 2: truck (confidence: 0.92)\n",
      "Frame 7: 2 vehicles detected\n",
      "  Vehicle 1: car (confidence: 0.94)\n",
      "  Vehicle 2: truck (confidence: 0.93)\n",
      "Frame 8: 2 vehicles detected\n",
      "  Vehicle 1: car (confidence: 0.94)\n",
      "  Vehicle 2: truck (confidence: 0.93)\n",
      "Frame 9: 2 vehicles detected\n",
      "  Vehicle 1: car (confidence: 0.94)\n",
      "  Vehicle 2: truck (confidence: 0.92)\n",
      "Video paused - press any key to continue\n",
      "Frame 10: 2 vehicles detected\n",
      "  Vehicle 1: car (confidence: 0.94)\n",
      "  Vehicle 2: truck (confidence: 0.92)\n",
      "Frame 11: 2 vehicles detected\n",
      "  Vehicle 1: car (confidence: 0.94)\n",
      "  Vehicle 2: truck (confidence: 0.92)\n",
      "Frame 12: 2 vehicles detected\n",
      "  Vehicle 1: car (confidence: 0.94)\n",
      "  Vehicle 2: truck (confidence: 0.92)\n",
      "Frame 13: 2 vehicles detected\n",
      "  Vehicle 1: car (confidence: 0.95)\n",
      "  Vehicle 2: truck (confidence: 0.92)\n",
      "Frame 14: 2 vehicles detected\n",
      "  Vehicle 1: car (confidence: 0.94)\n",
      "  Vehicle 2: truck (confidence: 0.92)\n",
      "Frame 15: 2 vehicles detected\n",
      "  Vehicle 1: car (confidence: 0.94)\n",
      "  Vehicle 2: truck (confidence: 0.92)\n",
      "Frame 16: 2 vehicles detected\n",
      "  Vehicle 1: car (confidence: 0.94)\n",
      "  Vehicle 2: truck (confidence: 0.92)\n",
      "User pressed 'q' - stopping video processing\n",
      "\n",
      "Processing Summary:\n",
      "- Frames processed: 16/795\n",
      "- Total vehicle detections: 32\n",
      "- Average detections per frame: 2.00\n",
      "Processing completed!\n",
      "\n",
      "Vehicle detection completed!\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a53a8e-7e8e-4541-98d5-086d84919d6a",
   "metadata": {},
   "source": [
    "### System Explanation\n",
    "\n",
    "This vehicle detection system works in the following steps:\n",
    "\n",
    "1. Load YOLOv4 model:\n",
    "The program uses OpenCV’s Deep Neural Network (DNN) module to load a pre-trained YOLOv4 model. It needs three files: yolov4.weights, yolov4.cfg, and coco.names. These files include the model’s structure, weights, and class labels.\n",
    "2.\tRead and process video:\n",
    "The video is opened using OpenCV. Each frame is resized to 416x416 pixels to match YOLO’s input size.\n",
    "3.\tDetect vehicles:\n",
    "    - Each frame is converted into a blob and sent to the YOLO network.\n",
    "    - The model detects all objects and returns bounding boxes with confidence scores.\n",
    "    - We filter only vehicle classes (car, bus, truck, motorcycle) based on COCO dataset IDs.\n",
    "4.\tRemove overlapping boxes:\n",
    "Non-Maximum Suppression (NMS) removes duplicate boxes for the same vehicle.\n",
    "5.\tShow results in real time:\n",
    "The program draws boxes and labels on each vehicle. It also shows the frame number, vehicle count, and total detections.\n",
    "6.\tUser controls:\n",
    "    - Press q to quit.\n",
    "    - Press space to pause/resume the video.\n",
    "\n",
    "This system is simple but effective for traffic monitoring and surveillance tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab625f3-6593-4cf6-90f3-6de4a9097e3a",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92248cd0-3cde-4619-a85f-1b5a206d514e",
   "metadata": {},
   "source": [
    "### What is mAP\n",
    "\n",
    "Mean Average Precision (mAP) is a standard evaluation metric for object detection models that combines both localization accuracy and classification performance across multiple object categories. It provides a single score to assess how well a model detects and classifies objects in images (Everingham et al., 2010)."
   ]
  },
  {
   "attachments": {
    "658c21d0-e3d0-49a3-b4be-58e951d6b1eb.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "c5ebbf1d-5c9e-44b6-ba75-544f0d6fd3ff",
   "metadata": {},
   "source": [
    "### Intersection over Union (IoU)\n",
    "\n",
    "Intersection over Union (IoU) measures the overlap between a predicted bounding box and the ground truth box. It is computed as the ratio of the area of overlap to the area of union between the two boxes.\n",
    "\n",
    "Formula:\n",
    "IoU = Area of Overlap / Area of Union\n",
    "\n",
    "A prediction is considered correct if the IoU is greater than or equal to a predefined threshold (e.g., 0.5). IoU is widely used in object detection benchmarks like PASCAL VOC and COCO (Everingham et al., 2010; Lin et al., 2014).\n",
    "\n",
    "![image.png](attachment:658c21d0-e3d0-49a3-b4be-58e951d6b1eb.png)\n",
    "\n",
    "*Source: PyImageSearch (Rosebrock, 2016)* "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2dc8bd2-b617-49b6-a24f-59e377e45a9a",
   "metadata": {},
   "source": [
    "### Precision and Recall\n",
    "\n",
    "Precision and Recall are key metrics for evaluating object detection models.  \n",
    "\n",
    "- Precision measures the proportion of correctly predicted positive detections out of all predicted positives. It answers: *“Of all the detections the model made, how many are correct?”*  \n",
    "  Formula: Precision = TP / (TP + FP)  \n",
    "\n",
    "- Recall measures the proportion of correctly predicted positive detections out of all actual positives. It answers: *“Of all the actual objects, how many did the model detect?”*  \n",
    "  Formula: Recall = TP / (TP + FN)  \n",
    "\n",
    "High precision means fewer false positives, while high recall means fewer false negatives. In object detection, there is often a trade-off between the two (*Everingham et al., 2010*).  \n",
    "\n"
   ]
  },
  {
   "attachments": {
    "a4b78128-aab4-4c15-a9de-74873d7ab208.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "286c4907-7ccb-49f3-b16e-5ab221b22f86",
   "metadata": {},
   "source": [
    "### Precision-Recall Curve\n",
    "\n",
    "The Precision-Recall (P-R) curve plots precision (y-axis) against recall (x-axis) at different confidence thresholds.  \n",
    "\n",
    "- As the detection threshold decreases, recall tends to increase because more objects are detected, but precision may decrease due to more false positives.  \n",
    "- The shape of the curve provides insights into the trade-off between precision and recall.  \n",
    "\n",
    "The area under the P-R curve represents Average Precision (AP), which summarizes the detection performance for one object class.  \n",
    "\n",
    "![image.png](attachment:a4b78128-aab4-4c15-a9de-74873d7ab208.png)\n",
    "\n",
    "P-R curves are widely used in benchmarks like PASCAL VOC and COCO to evaluate object detection models (*Everingham et al., 2010; Lin et al., 2014*).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c19992-68c0-4133-ab34-5e501679b6c1",
   "metadata": {},
   "source": [
    "### Average Precision (AP)\n",
    "\n",
    "Average Precision (AP) summarizes the shape of the Precision-Recall (P-R) curve into a single number. It is calculated as the area under the P-R curve for one object class.  \n",
    "\n",
    "- Step 1: Compute precision and recall values at different detection thresholds.  \n",
    "- Step 2: Plot the P-R curve.  \n",
    "- Step 3: Integrate (calculate the area) under the curve to obtain AP.  \n",
    "\n",
    "AP provides an overall score for how well a model detects and classifies instances of a single class. A perfect model would achieve AP = 1.0, while poor models have lower AP scores.  \n",
    "\n",
    "AP is widely used in benchmarks like PASCAL VOC (*Everingham et al., 2010*) and COCO (*Lin et al., 2014*) to compare object detectors.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dcc88e-af3e-42ad-a90f-6192f539f420",
   "metadata": {},
   "source": [
    "### Mean Average Precision (mAP)\n",
    "\n",
    "Mean Average Precision (mAP) extends Average Precision (AP) to multiple object classes. It is calculated by taking the mean of AP scores across all classes in a dataset.  \n",
    "\n",
    "- Step 1: Compute AP for each object class individually.  \n",
    "- Step 2: Take the average of all AP scores to get mAP.  \n",
    "\n",
    "mAP provides a single score to evaluate the overall performance of an object detector across multiple categories.  \n",
    "\n",
    "In PASCAL VOC, mAP is computed at a single IoU threshold (e.g., IoU ≥ 0.5). In COCO, mAP is calculated across multiple IoU thresholds (from 0.5 to 0.95 in steps of 0.05), making it a stricter and more comprehensive metric (*Everingham et al., 2010; Everingham et al., 2015; Lin et al., 2014*).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f0a6e-6928-48ae-8919-9d952d4b02b9",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "mAP provides a comprehensive evaluation metric for object detection models by combining localization accuracy (IoU) and classification performance (precision/recall) into a single score. It has become the standard evaluation metric in major computer vision benchmarks and competitions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77c1d76-9dfa-4e50-a8b7-f97d86e6c594",
   "metadata": {},
   "source": [
    "## References\n",
    "1. Dosovitskiy, A., Beyer, L., Kolesnikov, A., et al. (2020). *An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale.* arXiv preprint arXiv:2010.11929.  \n",
    "2. Tolstikhin, I., Houlsby, N., Kolesnikov, A., et al. (2021). *MLP-Mixer: An all-MLP Architecture for Vision.* Advances in Neural Information Processing Systems, 34.  \n",
    "3. Benz, P., Ham, S., Zhang, C., Karjauv, A., & Kweon, I. S. (2021). *Adversarial Robustness Comparison of Vision Transformer and MLP-Mixer to CNNs.* arXiv preprint arXiv:2110.02797.  \n",
    "4. Applied Sciences literature review on comparing ViT and CNN for image classification (2023). *Applied Sciences*, 13(9), 5521.\n",
    "5. OpenCV sample video (cars.mp4), provided with OpenCV library for educational use.\n",
    "6. Redmon, J., et al. (2016). You Only Look Once: Unified, Real-Time Object Detection. arXiv:1506.02640.\n",
    "7. OpenCV DNN Module Documentation: https://docs.opencv.org/\n",
    "8. Everingham, M., Van Gool, L., Williams, C. K. I., Winn, J., & Zisserman, A. (2010). The Pascal Visual Object Classes (VOC) Challenge. International Journal of Computer Vision, 88(2), 303-338.\n",
    "9. Rosebrock, A. (2016). Intersection over Union (IoU) for object detection. PyImageSearch. Retrieved from https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
    "10. Lin, T. Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., ... & Zitnick, C. L. (2014). Microsoft COCO: Common Objects in Context. arXiv preprint arXiv:1405.0312.\n",
    "11. Everingham, M., Eslami, S. M. A., Van Gool, L., Williams, C. K. I., Winn, J., & Zisserman, A. (2015). The Pascal Visual Object Classes Challenge: A Retrospective. International Journal of Computer Vision, 111(1), 98-136."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
